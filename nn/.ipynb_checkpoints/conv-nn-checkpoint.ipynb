{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = \"../input/normalized-images/\"\n",
    "data = pd.read_csv('../input/train.csv')\n",
    "available_list = np.array([os.path.splitext(filename)[0] for filename in os.listdir()])\n",
    "data = \n",
    "\n",
    "# Build X and y\n",
    "X_train = data[:, :-1]\n",
    "y_train = data[:, -1]\n",
    "X_test = data[:, :-1]\n",
    "y_test = data[:, -1]\n",
    "\n",
    "with tf.variable_scope('conv1') as scope:\n",
    "    kernel = _variable_with_weight_decay('weights',\n",
    "                                         shape=[5, 5, 3, 64],\n",
    "                                         stddev=5e-2,\n",
    "                                         wd=None)\n",
    "    conv = tf.nn.conv2d(images, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "    biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.0))\n",
    "    pre_activation = tf.nn.bias_add(conv, biases)\n",
    "    conv1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "    _activation_summary(conv1)\n",
    "\n",
    "# pool1\n",
    "pool1 = tf.nn.max_pool(conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1],\n",
    "                     padding='SAME', name='pool1')\n",
    "# norm1\n",
    "norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                name='norm1')\n",
    "\n",
    "# conv2\n",
    "with tf.variable_scope('conv2') as scope:\n",
    "kernel = _variable_with_weight_decay('weights',\n",
    "                                     shape=[5, 5, 64, 64],\n",
    "                                     stddev=5e-2,\n",
    "                                     wd=None)\n",
    "conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n",
    "pre_activation = tf.nn.bias_add(conv, biases)\n",
    "conv2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "_activation_summary(conv2)\n",
    "\n",
    "# norm2\n",
    "norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,\n",
    "                name='norm2')\n",
    "# pool2\n",
    "pool2 = tf.nn.max_pool(norm2, ksize=[1, 3, 3, 1],\n",
    "                     strides=[1, 2, 2, 1], padding='SAME', name='pool2')\n",
    "\n",
    "# local3\n",
    "with tf.variable_scope('local3') as scope:\n",
    "# Move everything into depth so we can perform a single matrix multiply.\n",
    "reshape = tf.reshape(pool2, [images.get_shape().as_list()[0], -1])\n",
    "dim = reshape.get_shape()[1].value\n",
    "weights = _variable_with_weight_decay('weights', shape=[dim, 384],\n",
    "                                      stddev=0.04, wd=0.004)\n",
    "biases = _variable_on_cpu('biases', [384], tf.constant_initializer(0.1))\n",
    "local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)\n",
    "_activation_summary(local3)\n",
    "\n",
    "# local4\n",
    "with tf.variable_scope('local4') as scope:\n",
    "weights = _variable_with_weight_decay('weights', shape=[384, 192],\n",
    "                                      stddev=0.04, wd=0.004)\n",
    "biases = _variable_on_cpu('biases', [192], tf.constant_initializer(0.1))\n",
    "local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)\n",
    "_activation_summary(local4)\n",
    "\n",
    "# linear layer(WX + b),\n",
    "# We don't apply softmax here because\n",
    "# tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits\n",
    "# and performs the softmax internally for efficiency.\n",
    "with tf.variable_scope('softmax_linear') as scope:\n",
    "weights = _variable_with_weight_decay('weights', [192, NUM_CLASSES],\n",
    "                                      stddev=1/192.0, wd=None)\n",
    "biases = _variable_on_cpu('biases', [NUM_CLASSES],\n",
    "                          tf.constant_initializer(0.0))\n",
    "softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)\n",
    "_activation_summary(softmax_linear)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
